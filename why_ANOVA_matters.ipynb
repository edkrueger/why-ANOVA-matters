{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why ANOVA Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample():\n",
    "    \"\"\"\n",
    "    Draws a sample of 100 independent observations from the same population.\n",
    "    In this case, the true population is standard normal.\n",
    "    \"\"\"\n",
    "    return np.random.normal(size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaination of Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_pairwise_t_test():\n",
    "    \n",
    "    \"\"\"\n",
    "    Draws two independent samples form the population and performs an independent t-test.\n",
    "    The t-test checks if the means of the samples are statistically different.\n",
    "    Returns True if the null is rejected; if the samples have statistically different means.\n",
    "    The significance level of the test is .05.\n",
    "    \"\"\"\n",
    "    \n",
    "    sample_1 = sample()\n",
    "    sample_2 = sample()\n",
    "\n",
    "    p_value = ttest_ind(sample_1, sample_2).pvalue\n",
    "\n",
    "    return p_value < .05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running 1000 t-tests on 1000 pairs of data drawn from the same distribution with significance level of .05, we should expect that approximately 50 false positives and a empirical false positive rate (FPR) of about .05.\n",
    "\n",
    "As an application, consider a drug test where one of the samples is from a control group and the other sample is from a group taking an experimental drug. Each observation is the (standardized) observation of some measurable medical test on an individual in the group. By assumption, since I've created the data generation process, I know that the drug actually does nothing; both groups actually come from the same population. However, researchers do not know this. Suppose there are 1000 research groups that are researching either the same or different non-effective drugs. If each group uses a significance level of .05 to test their results, about 50 groups will report that their drugs are effective!\n",
    "\n",
    "This is one reason why we should not trust medical results unless there is a plausible scientific explanation underlying the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "0.05\n"
     ]
    }
   ],
   "source": [
    "num_trials = 1000\n",
    "results = [do_pairwise_t_test() for _ in range(num_trials)]\n",
    "\n",
    "num_false_positives = results.count(True)\n",
    "empirical_FPR = num_false_positives / num_trials\n",
    "\n",
    "print(num_false_positives)\n",
    "print(empirical_FPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More than Two Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_all_way_pairwise_tests(num_groups, pairwise_sig):\n",
    "    \n",
    "    \"\"\"\n",
    "    Draw num_groups samples from the population.\n",
    "    Perform a t-test for every pair.\n",
    "    Report a result if any pairwise test is significant.\n",
    "    \"\"\"\n",
    "    \n",
    "    groups = [sample() for _ in range(num_groups)]\n",
    "    \n",
    "    pairs = combinations(groups, r=2)\n",
    "\n",
    "    return any(\n",
    "        [ttest_ind(pair[0], pair[1]).pvalue < pairwise_sig for pair in pairs]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n",
      "0.111\n"
     ]
    }
   ],
   "source": [
    "num_trials = 1000\n",
    "results = [do_all_way_pairwise_tests(num_groups=3, pairwise_sig=.05) for _ in range(num_trials)]\n",
    "\n",
    "num_false_positives = results.count(True)\n",
    "empirical_FPR = num_false_positives / num_trials\n",
    "\n",
    "print(num_false_positives)\n",
    "print(empirical_FPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of having a FPR that we would hope for by specifying the significance as .05. We get many more false positive rates than we would hope for.\n",
    "\n",
    "Since we have 3 samples, we have to make 3 pairwise tests each with significance of .05. If any of these tests cause us to reject the null, we will declare a false positive. So, under the assumption of independence, we can theoretically see that this testing process will results in a FPR of $1−(1−.05)^{3}=0.142625$. (Since, in practice, a set of random samples of finite length will almost never have 0 covariance, the tests will actually be correlated producing a FPR lower than the theoretical expectation.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
