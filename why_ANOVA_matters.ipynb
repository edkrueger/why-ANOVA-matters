{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why ANOVA Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample():\n",
    "    \"\"\"\n",
    "    Draws a sample of 100 independent observations from the same population.\n",
    "    In this case, the true population is standard normal.\n",
    "    \"\"\"\n",
    "    return np.random.normal(size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_all_way_pairwise_tests(num_groups, pairwise_sig):\n",
    "    \n",
    "    \"\"\"\n",
    "    Draws num_groups independent samples form the population\n",
    "    and performs an independent t-test for every pair at significance pairwise_sig.\n",
    "    Each of the t-tests checks if the means of the pairs of samples are statistically different.\n",
    "    Reports a result if any pairwise test is significant.\n",
    "    \n",
    "    When num_groups=2, this function is equivalent to drawing 2 indpendent samples from a population\n",
    "    and performing a t-test.\n",
    "    \"\"\"\n",
    "    \n",
    "    groups = [sample() for _ in range(num_groups)]\n",
    "    \n",
    "    pairs = combinations(groups, r=2)\n",
    "\n",
    "    return any(\n",
    "        [ttest_ind(pair[0], pair[1]).pvalue < pairwise_sig for pair in pairs]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaination of Significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running 1000 t-tests on 1000 pairs of data drawn from the same distribution with significance level of .05, we should expect that approximately 50 false positives and a empirical false positive rate (FPR) of about .05.\n",
    "\n",
    "As an application, consider a drug test where one of the samples is from a control group and the other sample is from a group taking an experimental drug. Each observation is the (standardized) observation of some measurable medical test on an individual in the group. By assumption, since I've created the data generation process, I know that the drug actually does nothing; both groups actually come from the same population. However, researchers do not know this. Suppose there are 1000 research groups that are researching either the same or different non-effective drugs. If each group uses a significance level of .05 to test their results, about 50 groups will report that their drugs are effective!\n",
    "\n",
    "This is one reason why we should not trust medical results unless there is a plausible scientific explanation underlying the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "0.049\n"
     ]
    }
   ],
   "source": [
    "num_trials = 1000\n",
    "results = [do_all_way_pairwise_tests(num_groups=2, pairwise_sig=.05) for _ in range(num_trials)]\n",
    "\n",
    "num_false_positives = results.count(True)\n",
    "empirical_FPR = num_false_positives / num_trials\n",
    "\n",
    "print(num_false_positives)\n",
    "print(empirical_FPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More than Two Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n",
      "0.112\n"
     ]
    }
   ],
   "source": [
    "num_trials = 1000\n",
    "results = [do_all_way_pairwise_tests(num_groups=3, pairwise_sig=.05) for _ in range(num_trials)]\n",
    "\n",
    "num_false_positives = results.count(True)\n",
    "empirical_FPR = num_false_positives / num_trials\n",
    "\n",
    "print(num_false_positives)\n",
    "print(empirical_FPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of having a FPR that we would hope for by specifying the significance as .05. We get many more false positive rates than we would hope for.\n",
    "\n",
    "Since we have 3 samples, we have to make 3 pairwise tests each with significance of .05. If any of these tests cause us to reject the null, we will declare a false positive. So, under the assumption of independence, we can theoretically see that this testing process will results in a FPR of $1−(1−.05)^{3}=0.142625$. (Since, in practice, a set of random samples of finite length will almost never have 0 covariance, the tests will actually be correlated producing a FPR lower than the theoretical expectation.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an example, consider that there are 1000 groups of researchers studying the effects of 3 (completely irrelevant) diets. Since its hard to decide on which diet would represent a control diet, we can assume that the researchers would perform every pairwise test. This would result in around 133 groups reporting positive results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "929\n",
      "0.929\n"
     ]
    }
   ],
   "source": [
    "num_trials = 1000\n",
    "results = [do_all_way_pairwise_tests(num_groups=20, pairwise_sig=.05) for _ in range(num_trials)]\n",
    "\n",
    "num_false_positives = results.count(True)\n",
    "empirical_FPR = num_false_positives / num_trials\n",
    "\n",
    "print(num_false_positives)\n",
    "print(empirical_FPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have 20 different treatments in each study, we see that almost every study will produce a positive result. This is because the number of tests do not scale linearly. There are 3 pairwise tests between 3 groups, 6 pairwise tests between 4 groups and 190 pairwise tests between 20 groups. This is easy to visualize as the edges in a complete graph (see https://en.wikipedia.org/wiki/Complete_graph#Examples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonferroni Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple and intuitive solution to the problem of having too many false positives in multiple testing is Bonferroni correction. The idea is that we divide each of our test's significances by the number of tests. That is, if we want our multiple testing process to have a FPR of .05, and have 3 test, we adjust the significance of each tests to $\\frac{.05}{3} \\approx 0.0167$.\n",
    "\n",
    "Theoretically, under the assumption of independence of tests, this results in a FPR of $1 - (1 - \\frac{\\alpha}{k})^{k}$, where $\\alpha$ is the significance and $k$ is the number of tests. For the significance level of .05 with three hypothesis tests, this results in a FPR of $1 - (1 - \\frac{.05}{3})^3 \\approx 0.0492$.\n",
    "\n",
    "Even theoretically under the assumption of independent samples, we see that the test is slightly too conservative as 0.04917 is slightly less than 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "0.041\n"
     ]
    }
   ],
   "source": [
    "num_trials = 1000\n",
    "results = [do_all_way_pairwise_tests(num_groups=3, pairwise_sig=.05/3) for _ in range(num_trials)]\n",
    "\n",
    "num_false_positives = results.count(True)\n",
    "empirical_FPR = num_false_positives / num_trials\n",
    "\n",
    "print(num_false_positives)\n",
    "print(empirical_FPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empirically, we see that the test is even more conservative than we theoretically expect. We get a FPR of about 0.043. This is because the group samples do not empirically have 0 correlation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
